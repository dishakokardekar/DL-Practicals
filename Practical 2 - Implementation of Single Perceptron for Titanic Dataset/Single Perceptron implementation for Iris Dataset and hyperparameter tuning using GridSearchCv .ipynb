{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dccf2383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_path = 'C:\\\\Users\\\\91901\\\\Downloads\\\\archive\\\\iris_tidy.csv'\n",
    "df = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80582fc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Species</th>\n",
       "      <th>Part</th>\n",
       "      <th>Measure</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>setosa</td>\n",
       "      <td>Sepal</td>\n",
       "      <td>Length</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>Sepal</td>\n",
       "      <td>Length</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>setosa</td>\n",
       "      <td>Sepal</td>\n",
       "      <td>Length</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>setosa</td>\n",
       "      <td>Sepal</td>\n",
       "      <td>Length</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>setosa</td>\n",
       "      <td>Sepal</td>\n",
       "      <td>Length</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>596</td>\n",
       "      <td>virginica</td>\n",
       "      <td>Petal</td>\n",
       "      <td>Width</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>597</td>\n",
       "      <td>virginica</td>\n",
       "      <td>Petal</td>\n",
       "      <td>Width</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>598</td>\n",
       "      <td>virginica</td>\n",
       "      <td>Petal</td>\n",
       "      <td>Width</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>599</td>\n",
       "      <td>virginica</td>\n",
       "      <td>Petal</td>\n",
       "      <td>Width</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>600</td>\n",
       "      <td>virginica</td>\n",
       "      <td>Petal</td>\n",
       "      <td>Width</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0    Species   Part Measure  Value\n",
       "0             1     setosa  Sepal  Length    5.1\n",
       "1             2     setosa  Sepal  Length    4.9\n",
       "2             3     setosa  Sepal  Length    4.7\n",
       "3             4     setosa  Sepal  Length    4.6\n",
       "4             5     setosa  Sepal  Length    5.0\n",
       "..          ...        ...    ...     ...    ...\n",
       "595         596  virginica  Petal   Width    2.3\n",
       "596         597  virginica  Petal   Width    1.9\n",
       "597         598  virginica  Petal   Width    2.0\n",
       "598         599  virginica  Petal   Width    2.3\n",
       "599         600  virginica  Petal   Width    1.8\n",
       "\n",
       "[600 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2feaa0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0      int64\n",
      "Species        object\n",
      "Part           object\n",
      "Measure        object\n",
      "Value         float64\n",
      "dtype: object\n",
      "['Sepal' 'Petal']\n",
      "Unnamed: 0      0\n",
      "Species         0\n",
      "Part          600\n",
      "Measure         0\n",
      "Value           0\n",
      "dtype: int64\n",
      "Unnamed: 0    0.0\n",
      "Species       0.0\n",
      "Part          0.0\n",
      "Measure       0.0\n",
      "Value         0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('C:\\\\Users\\\\91901\\\\Downloads\\\\archive\\\\iris_tidy.csv')\n",
    "\n",
    "print(df.dtypes)\n",
    "print(df['Part'].unique())\n",
    "df['Part'] = pd.to_numeric(df['Part'], errors='coerce')\n",
    "\n",
    "print(df.isnull().sum())\n",
    "df.dropna(subset=['Part'], inplace=True)\n",
    "\n",
    "print(df.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a0fde74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: Species, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "target = df.Species\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdcf6df2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0.0\n",
       "Species       0.0\n",
       "Part          0.0\n",
       "Measure       0.0\n",
       "Value         0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd2fe181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 75 candidates, totalling 375 fits\n",
      "Best Parameters: {'perceptron__alpha': 0.0001, 'perceptron__max_iter': 100, 'perceptron__tol': 0.001}\n",
      "Best Score: 0.8833333333333332\n",
      "Test Score: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline with standard scaler and perceptron\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('perceptron', Perceptron())\n",
    "])\n",
    "\n",
    "# hyperparameters grid for tuning\n",
    "param_grid = {\n",
    "    'perceptron__alpha': [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "    'perceptron__max_iter': [100, 200, 300, 400, 500],\n",
    "    'perceptron__tol': [1e-3, 1e-4, 1e-5]\n",
    "}\n",
    "\n",
    "# GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "test_score = grid_search.score(X_test, y_test)\n",
    "print(\"Test Score:\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18d00b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.28888888888888886\n",
      "Precision: 0.08345679012345678\n",
      "Recall: 0.28888888888888886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91901\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, learning_rate=0.01, epochs=100):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def initialize_weights(self, n_features):\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_output = np.dot(X, self.weights) + self.bias\n",
    "        return np.where(linear_output >= 0, 1, 0)  # Step function as activation\n",
    "\n",
    "    def train(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.initialize_weights(n_features)\n",
    "        for _ in range(self.epochs):\n",
    "            for i in range(n_samples):\n",
    "                linear_output = np.dot(X[i], self.weights) + self.bias\n",
    "                y_pred = np.where(linear_output >= 0, 1, 0)  # Step function\n",
    "                # Update weights and bias\n",
    "                self.weights += self.learning_rate * (y[i] - y_pred) * X[i]\n",
    "                self.bias += self.learning_rate * (y[i] - y_pred)\n",
    "\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the perceptron\n",
    "perceptron = Perceptron(learning_rate=0.01, epochs=100)\n",
    "perceptron.train(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = perceptron.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe668240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9333333333333333\n",
      "Precision: 0.8947368421052632\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, learning_rate=0.1, epochs=100):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def initialize_weights(self, n_features):\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_output = np.dot(X, self.weights) + self.bias\n",
    "        return np.where(linear_output >= 0, 1, 0)  # Step function as activation\n",
    "\n",
    "    def train(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.initialize_weights(n_features)\n",
    "        for _ in range(self.epochs):\n",
    "            for i in range(n_samples):\n",
    "                linear_output = np.dot(X[i], self.weights) + self.bias\n",
    "                y_pred = np.where(linear_output >= 0, 1, 0)  # Step function\n",
    "                # Update weights and bias\n",
    "                self.weights += self.learning_rate * (y[i] - y_pred) * X[i]\n",
    "                self.bias += self.learning_rate * (y[i] - y_pred)\n",
    "\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Consider only the first two features and first 100 samples for binary classification\n",
    "X = X[:100, :2]\n",
    "y = np.where(y[:100] == 0, 1, 0)  # Convert to binary labels (0 or 1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "perceptron = Perceptron(learning_rate=0.1, epochs=100)\n",
    "perceptron.train(X_train, y_train)\n",
    "\n",
    "y_pred = perceptron.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411163ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
